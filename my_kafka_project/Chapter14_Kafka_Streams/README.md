- 이 장에서 사용하는 API는 아파치 카프카 2.8을 기준으로한다.
	- 3.0의 조인 연산의 의미 구조나 타임스탬프 처리는 다루지 않는다.


## 스트림 처리란 무엇인가?

- 데이터 스트림
	- 스트림 프로세싱의 세계는 여전히 진화중이며 모든 스트림 프로세싱 시스템이 저마다의 구현과 제약이 존재한다.
	- 이벤트 스트림은 무한 데이터세트를 나타내는 추상 개념이라 할 수 있다.
		- 시간이 흐름에 따라 새로운 레코드가 계속해서 추가되기 때문에 데이터세트가 무한해지는 것


이벤트 스트림에는 다음과 같은 속성이 존재한다.

#### 이벤트 스트림에는 순서가 있다.

- 본질적으로 이벤트는 다른 이벤트 전이나 후에 발생한다.
- 관계형 데이터베이스의 경우 항상 순서가 없는 것으로 간주하지만, 이벤트 스트림은 명확한 순서가 존재한다.


#### 데이터 레코드는 불변(immutable)하다.

- 이벤트는 한 번 발생한 뒤에는 절대 변경할 수 없다.
- 이벤트 스트림은 모든 트랜잭션을 포함하기 때문에 모든 작업 내역이 기록된다.
	- 레코드를 테이블에 추가한 뒤 삭제하면 해당 테이블을 더 이상 레코드를 포함하고 있지 않지만, redo log는 추가와 삭제하는 두 개의 트랜잭션을 포함하고 있다.

#### 이벤트 스트림은 재생(replay)이 가능하다.

- 카프카는 이벤트 스트림을 캡처하고 또 재생할 수 있다.
- 몇 달 전 심지어 몇 년 전 row 스트림을 그대로 재생할 수도 있다.
	- 이는 에러를 수정하거나 스트림의 새로운 분석 방법을 시도하거나, 감사를 수행하기 위함이다.


스트림 처리란 하나 이상의 이벤트 스트림을 계속해서 처리하는 것을 의미한다. **스트림 처리**는 **요청-응답**, **배치 처리**와 마찬가지로 <span style='color:#f7b731'>프로그래밍 패러다임 중 하나</span>이다.


#### 요청-응답

- 1밀리초 이하에 수 밀리초까지의 짧은 응답 시간을 가진다.
- 애플리케이션이 요청을 전송한 후 처리 시스템이 응답을 보내 줄 때까지 대기해야한다.
- 데이터베이스에서 이 패러다임이 OLTP(Online Transaction Processing)으로 알려져 있다.


#### 배치 처리

- 지연이 크지만, 처리량도 방대하다.
- 이 프로세싱 시스템은 설정된 시간에 시작된다. 
	- 매일 새벽 2시, 매 시간 등등 사전 설정된 시간


#### 스트림 처리

- 연속적이며 중단되지 않는 패러다임이고, 요청-응답과 배치 프로세싱 간의 격차를 줄여준다.
- 대부분의 프로세스는 수밀리초 이내의 즉시 응답을 요구하지 않지만, 그렇다고 다음 날까지 기다려주지도 않는다.
- 대부분의 비즈니스 프로세스는 연속적으로 발생한다.
	- 물품 배달 추적, 신용카드 거래 사용 내역의 알림, 수요와 공급에 기반을 둔 실시간 가격 조정 등과 같은 비즈니스는 지속적이지만 중단되지 않는 프로세싱에 해당한다.


#### 요약

무한 데이터세트로부터 계속해서 데이터를 읽고, 처리하고, 출력을 내보낸다면 그 자체로 스트림 프로세싱이라고 한다.

단 지속적으로 계속 진행되는 것이어야 한다. 예를 들어 매일 오전 2시에 시작해서 스트림으로부터 500개의 레코드를 읽고 결과를 출력한 후 종료한다면 그것은 스트림 처리 프로세스라고 할 수 없다.
   


## 스트림 처리 개념

### 토폴로지(topology)

- 스트림 처리 애플리케이션은 하나 이상의 처리 토폴로지를 포함한다.
- 하나의 처리 토폴로지는 하나 이상의 소스 스트림(), 스트림 프로세서()의 그래프, 하나 이상의 싱크 스트림()이 서로 연결된 것이다. 
- 각각의 스트림 프로세서는 이벤트를 변환하기 위해 이벤트 스트림에 가해지는 연상 단계라고 할 수 있다.


### 시간(time)

스트림 처리에서 **가장 중요한 개념**이다. 스트림 처리 시스템은 보통 다음과 같은 시간 개념들을 사용하는데, 한번 살펴보자.

#### 이벤트 시간

- 다루고자 하는 이벤트가 발생하여 레코드가 생성된 시점이다.
- 카프카는 0.10.0 이후로 자동으로 프로듀서 레코드 생성 시간을 추가하고 있다.


#### 로그 추가 시간

- 이벤트가 카프카 브로커에 전송되어 저장된 시점이며, 접수 시간(ingestion time)이라고도 불린다.
- 카프카 브로커는 자동으로 수신한 레코드에 로그 추가 시간을 추가하고 있습니다.
- 스트림 처리에서는 이벤트 발생 시간이 관심사이므로 로그 추가 시간은 덜 중요하다.


#### 처리 시간

- 스트림 처리 애플리케이션이 연산을 수행하기 위해 이벤트를 받은 시간이다.
- 이 시간 개념은 신뢰성이 매우 낮다. 
	- 같은 애플리케이션 안에서도 스레드별로 다를 수 있고, 언제 스트림 처리 애플리케이션이 이벤트를 읽었는지에 따라서 항상 달라질 수 있다.

- 카프카 스트림즈는 `TimestampExtractor 인터페이스`를 사용해서 각각의 이벤트에 시간을 부여한다.
	- 카프카 스트림즈를 사용하는 개발자는 이 인터페이스의 서로 다른 구현체를 사용함으로써 위의 세 가지 시간 개념 중 하나를 사용하거나, 이벤트 내용에서 타임스탬프를 결정하는 등의 완전히 다른 시간 개념을 사용할 수도 있다.
- 시간을 다룰 때는 타임존에 주의해야 한다. 
	- 전체 데이터 파이프라인이 단일 타임존을 적용해야 한다.
	- 그래서 레코드에 시간대 정보를 저장하는 경우도 있다고 한다.


### 상태

 카프카에서 온라인 쇼핑 트랜잭션 스트림을 읽어 $10,000 달러 이상의 트랜잭션들을 찾은 후, 판매 담당자에게 메일을 보내는 것은 컨슈머와 SMTP를 사용하면 몇 줄의 코드로 충분할 것 이지만, 다수의 이벤트가 포함되는 작업을 갖는 스트림 프로세싱은 복잡할 수 있다.
 
지금 한 시간 동안 발생한 타입별 이벤트 수나 조인, 합계 및 평균을 계산해야 하는 모든 이벤트등 더 많은 정보를 추적 관리해야 한다. 이러한 정보를 **상태** 라고 한다.

스트림 처리에는 다음과 같은 유형의 상태가 존재한다.

#### 로컬 또는 내부 상태

- 스트림 프로세싱 애플리케이션의 **특정 인스턴스**에서만 사용할 수 있는 상태이다.
- 이 상태는 대개 애플리케이션에 포함되어 <span style='color:#f7b731'>내장형 인메모리 DB를 사용해서 유지 관리</span>된다.


#### 외부 상태

- 외부 데이터 저장소에서 유지되는 상태는 카산드라와 같은 NoSQL 시스템을 사용해서 저장된다.
- 많은 스트림 처리 애플리케이션은 외부 저장소의 사용을 피하거나 **데이터를 로컬 캐시에 유지 관리**하여 <span style='color:#f7b731'>외부 시스템과의 통신을 최소화하여 지연 부담을 줄인다.</span>


### 스트림-테이블 이원성

- 테이블에서의 레코드는 변이가 가능하며, **변경의 최종 결과 상태**를 나타낸다.
	- 테이블이 과거의 변경 내역을 저장하도록 특별히 설계된 것이 아니라면 과거 연락처를 찾을 수 없다.
- 스트림은 변경 내역을 저장한다.
	- 스트림은 변경을 유발하는 이벤트의 연속이다.
- <span style='color:#f7b731'>테이블을 스트림으로 변경하기 위해서는 테이블을 수정하는 모든 이벤트(추가, 변경, 삭제)를 받아서 스트림에 저장</span>해야한다.
	- 이를 위해 많은 DB에서는 **데이터 캡처(Change Data Capture, CDC) 솔루션**을 제공한다.
	- 이런 변경점을 스트림 처리에 활용할 수 있도록 카프카로 전달할 수 있는 **카프카 커넥터**가 많이 존재하고 있다.
- 반대로 <span style='color:#f7b731'>스트림을 테이블로 변환하기 위해서는 스트림이 포함하는 모든 변경사항을 테이블에 적용</span>해야 하며, 이를 스트림의 **구체화(materializing)** 라고 한다.
	- 메모리, 내부 상태 저장소, 외부 DB 중 하나에 테이블을 생성하고, <span style='color:#f7b731'>스트림의 처음부터 끝까지 모든 이벤트를 읽어서 상태를 변경</span>한다.
	    

### 시간 윈도우(Time window)

- 대부분의 스트림 작업은 시간을 윈도우라 불리는 구간 단위로 잘라서 처리한다.
	- 이동 평균 계산, 한 주간 가장 많이 팔린 상춤 계산, 시스템의 99분위 부하를 찾는 식이다.
- 예를 들어서 이동 평균을 계산할 때 다음과 같은 사항들을 고려해야 한다.

#### 윈도우 크기

- 모든 이벤트의 평균을 매 5분 또는 15분 또는 하루 중의 어떤 타임 윈도우로 산출할 것인지를 결정해야 한다. 윈도우가 커질수록 이동 평균은 완만해지지만, 그만큼 랙(lag)도 커진다.


#### 시간 윈도우의 진행 간격

- 5분 단위 평균은 매분, 매초, 새로운 이벤트가 도착할 때마다 업데이트 될 수 있다.
	- 윈도우의 크기와 윈도우 사이의 고정된 시간 간격이 같은 윈도우를 **호평 윈도우(hopping window)** 라고 한다.
	- 진행 간격(advance interval)과 윈도우의 크기가 같은 경우를 **텀블링 윈도우(tumbling window)** 라고 한다.
- ![[Pasted image 20240116085535.png]]


#### 윈도우를 업데이트할 수 있는 시간

- 만약 00:00 ~ 00:05 까지의 윈도우에 대해 5분 단위 이동평균을 계산했다고 했을 때 한 시간 뒤, 00:02의 이벤트 시간에 추가될 결과 값을 얻게되었다면 어떻게 해야할까?
- <span style='color:#f7b731'>이벤트가 추가되는 특정 시간대의 윈도우를 정의하는 것이 이상적</span>이다. 가령, 이벤트를 4시간 늦게까지 받는다면 그것으로 산출되는 결과값을 다시 계산하여 변경하고, 4시간 이후의 이벤트는 무시하면 된다.


### 처리 보장

- 카프카 스트림즈 라이브러리를 사용하는 모든 애플리케이션은 `processing.guarantee` 설정을 `exactly_once`로 잡아줌으로써 **정확히 한 번 보장 기능**을 활성화 할 수있다.
	- 지금은 변경되었음
	- 카프카 버전 3.0 부터는 `exactly_once_v2`를 사용할 것을 권장한다.



## 스트림 처리 디자인 패턴

- **모든 스트림 프로세싱 시스템은 서로 다르다.**
- 컨슈머와 처리 로직 및 프로듀서를 조합한 것이 있는가 하면, 클러스터 상에서 머신 러닝 기반의 스파크 스트리밍 같은 것들도 존재한다.
- 스트림 처리 아키텍처의 공통적인 요구사항에 대한 잘 알려진 해법인 기본 패턴이 있다.


### 단일 이벤트 처리

- 각 이벤트를 개별적으로 처리하는 **가장 기본적인 스트림 처리 패턴**이다.
- 이 패턴의 스트림 처리 애플리케이션은 스트림으로부터 이벤트를 읽고 각각의 이벤트를 수정한 뒤, 다른 스트림에 쓴다.


### 로컬 상태와 스트림 처리

- 카프카 스트림의 <span style='color:#f7b731'>상태 정보를 공유 상태가 아니라 로컬 상태를 사용해서 수행</span>할 수 있다.
- 예를 들어, 주식 최저가와 평균가를 계산하기 위해 최소값과, 총합, 지금까지 본 레코드 수를 저장해야 하는데, 이럴 때 로컬 상태를 사용할 수 있다.
- 카프카 파티셔너를 사용해서 동일한 주식에 대한 모든 이벤트를 동일한 파티션에 쓰도록 하고, 애플리케이션의 각 인스턴스에서 자신에게 할당된 파티션에 저장된 모든 이벤트를 읽어오면 된다.
- 즉, 애플리케이션의 각 인스턴스는 자신에게 할당된 파티션에 쓰여진 주식 종목의 상태를 유지할 수 있다는 것이다.


스트림 처리 애플리케이션은 로컬 상태를 보유하는 순간 훨씬 복잡해지는데, 고려해야 할 사항에는 다음과 같은 것들이 있다.

- 메모리 사용
	- 로컬 상태는 애플리케이션 인스턴스가 사용 가능한 메모리 안에 들어갈 수 있는게 이상적이다.
- 영속성
	- 우리는 애플리케이션 인스턴스가 종료되었을 때 상태가 유실되지 않을뿐더러 인스턴스가 재실행 되거나 다른 인스턴스에 의해 대체되었을 때 <span style='color:#f7b731'>복구될 수 있음을 확신할 수 있어야 한다.</span>
- 리밸런싱
	- 파티션은 이따금 서로 다른 컨슈머에게 다시 할당될 수 있다.


### 다단계 처리/리파티셔닝

- 만약 매일 상위 10개의 주식을 계산해야 한다면 어떻게 해야할까?
- 로컬 상태를 가지고 있는 각 인스턴스에서 각 종목별 주가 상승/하락을 산출한 후 하나의 파티션만 가진 새로운 토픽에 결과를 쓴다.
- 그리고 이 파티션을 하나의 애플리케이션 인스턴스가 읽어서 매일 상위 10개 주식을 찾는다.


### 외부 검색을 사용하는 처리: 스트림-테이블 조인

- 스트림 처리를 할 때 때로는 외부 데이터를 스트림과 조인할 경우가 있다.
- 예를 들어, 클릭 이벤트가 발생해서 스트림으로 들어올 때마다 유저 DB를 조회해서 사용자를 찾는다면 상당한 지연을 발생시킬 수 있기 때문에 <span style='color:#f7b731'>스트림 처리 애플리케이션 안에 DB 데이터를 캐시</span>해야 한다.
- <span style='color:#f7b731'>DB의 변경 내역을 이벤트 스트림으로 받아오는 것</span>을 **CDC(change data capture)** 라고 하며, 카프카 커넥트는 CDC를 수행하여 DB 테이블을 변경 이벤트 스트림으로 변환할 수 있는 커넥터가 여럿 존재한다.


### 테이블-테이블 조인

- 카프카 스트림에서는 동일한 방식으로 파티션된 동일한 키를 가지는 두 개의 테이블에 대해 **동등 조인(equi-join)** 을 수행할 수 있고, 이렇게 함으로써 <span style='color:#f7b731'>조인 연산이 많은 수의 애플리케이션 인스턴스와 장비에 효율적으로 분산</span>될 수 있게 한다.


### 스트리밍 조인(윈도우 조인, window join)

- 때로는 두 개의 **실제 이벤트 스트림을 조인**해야하는 경우가 존재한다.
- 스트림은 무한이라는 특성을 가진다.
- 즉, 두 개의 스트림을 조인할 경우 한쪽 스트림에 포함된 이벤트를 같은 키값과 함께 같은 시간 윈도우에 발생한 다른 쪽 스트림 이벤트와 맞춰야하기 때문에 <span style='color:#f7b731'>과거와 현재의 이벤트 전체를 조인</span>하게 된다.
	- 때문에 <span style='color:#f7b731'>스트리밍 조인을 </span>**윈도우 조인**이라고도 부른다.


### 비순차 이벤트

- **잘못된 시간에 도착한 이벤트(비순차 이벤트, out-of-sequence)** 는 상당히 자주 발생할 수 있으며, 이것을 처리하는 것은 스트림 처리에서 쉽지 않은 일이다.
- 이런 상황을 처리하기 위해서 다음과 같은 일들을 해야 한다.
	- 이벤트 순서를 벗어났음을 알아야 한다.
	- 비순차 이벤트의 순서를 복구할 수 있는 시간 영역을 정의한다.
	- 순서를 복구하기 위해 이벤트를 묶을 수 있어야 한다.
	- 결과를 변경할 수 있어야 한다.


### 재처리하기


## 예제로 보는 카프카 스트림즈
- chapter14.4 p. 443
- 블로그 올리기 전 예제 해보기



## 카프카 스트림즈: 아키텍처 개요

**카프카 스트림즈 라이브러리**가 실제로 어떻게 작동하고 규모를 확장시키는지에 대해 더 잘 이해해보기 위해 내부의 메커니즘을 이해해보자


### 토폴로지 생성하기

- 모든 스트림즈 애플리케이션은 **하나의 토폴로지를 구현하고 실행**한다.
- 토폴로지는 모든 이벤트가 입력에서 출력으로 이동하는 동안 <span style='color:#f7b731'>수행되는 작업과 변환 처리의 집합</span>이라고 할 수 있다.
	- 토폴로지는 다른 프레임워크에서는 유향 비순환 그래프(directd acyclic graph, DAG)라고도 불린다.
- 단순한 애플리케이션이라고 해도 나름 복잡한 토폴로지가 존재한다.
- 토폴로지는 프로세서들로 구성되며, 그것들은 토폴로지 그래프의 노드에 대응한다.
- 대부분의 프로세서는 필터, 맵, 집계 연산과 같은 **데이터 처리 작업을 구현**합니다.
- 토픽으로부터 데이터를 읽어 전달하는 **소스 프로세서(source processor)** 가 존재하며, 이전의 프로세서로부터 데이터를 받아 토픽에 쓰는 **싱크 프로세서(sink processor)** 도 존재한다.
- 토폴로지는 <span style='color:#f7b731'>항상 하나 이상의 소스 프로세서로 시작해 한 개 이상의 싱크 프로세서로 끝난다.</span>


### 토폴로지 최적화하기

기본적으로, 카프카 스트림즈는 **DSL(Domain-Specific Languages) API**를 사용해서 개발된 애플리케이션의 <span style='color:#f7b731'>각 DSL 메서드를 독립적으로 저수준 API로 변환</span>하여 실행한다. DSL 메서드를 독립적으로 변환하기 때문에 **결과는 그리 최적화되지 않을 상태**일 수 있다.


카프카 스트림즈 애플리케이션의 실행은 아래 3단계로 이루어진다.

1. `KStream`, `KTable` 객체를 생성하고 여기에 필터, 조인과 같은 DSL 작업을 수행함으로써 <span style='color:#f7b731'>논리적 토폴리지를 정의</span>한다.
2. `Streamsbuilder.build()` 메서드가 <span style='color:#f7b731'>논리적 토폴로지로부터 물리적 토폴로지를 생성</span>한다.
	- 이 단계가 최적화가 적용되는 단계다.
3. `KafkaStreams.start()`가 토폴로지를 실행시킨다.
	- 데이터를 읽고, 처리하고 쓰는 곳이 여기다.

이 기능은 `StreamsConfig.TOPOLOGY_OPTIMIZATION` 설정값을 `StreamsCongig.OPTIMIZE`로 잡아준 뒤 `build(props)`를 호출 함으로써 활성화시킬 수 있다.

애플리케이션을 테스트할 때는 최적화 된 것과 안된 것을 비교해서 실행 시간과 카프카에 쓰여지는 데이터의 양을 비교해 보는 것이 좋다.(다양한 상황에서 결과물이 동일한지 확인해야 한다.)


### 토폴로지 테스트하기

- 스트림 처리 애플리케이션을 테스트하기 위해서는 `TopologyTestDriver`을 사용하면 된다.
	- 하지만 카프카 스트림즈의 캐시 기능을 시뮬레이션해주지는 않으므로 찾을 수 없는 에러도 많다.
- 카프카 스트림즈의 경우 `EmbeddedKafkaCluster`와 `Testcontainers`의 두 통합 테스트 프레임워크를 자주 사용한다.
	- `EmbeddedKafkaCluster`는 JVM상에 카프카 프로커를 띄우는 방식이다.
	- `Testcontainers`는 도커 컨테이너를 사용해서 카프카 브로커와 기타 테스트에 필요한 다른 요소들을 띄워주는 방식이다.


### 토폴로지 규모 확장하기

- 카프카 스트림즈는 하나의 애플리케이션 인스턴스 안에 다수의 스레드가 실행될 수 있게 함으로써 규모 확장과 서로 다른 애플리케이션 인스턴스 간의 **부하 분산(load balancing)** 이 이루어지도록 한다.
- **카프카 스트림즈 엔진**은 토폴로지의 실행을 다수의 태스크로 분할하여 병렬 처리한다.
- 카프카 스트림즈 엔진은 애플리케이션이 처리하는 토픽의 파티션 개수에 따라 태스크 수를 결정한다.
- 각 태스크는 전체 파티션 중 일부의 처리를 책임진다.
- 애플리케이션 개발자는 애플리케이션 인스턴스가 실행시킬 스레드의 수를 결정할 수 있다.
- 만약 다수의 스레드를 활용할 수 있다면, 각각의 스레드는 해당 애플리케이션이 생성하는 전체 태스크의 일부를 실행하게 된다.
- 만약 다수의 애플리케이션의 인스턴스가 다수의 서버에서 실행될 경우,각 서버의 스레드별로 서로 다른 테스크가 실행될 것이다.
- 이것이 스트리밍 애플리케이션이 규모를 확장하는 방법이다.


### 장애처리하기

- <span style='color:#f7b731'>앞의 설명한 모델(토폴로지 규모 확장하기)</span>은 장애를 처리하는데 도움을 준다.
- 만약 애플리케이션에 장애가 생겨 재시작이 필요할 때, 장애가 생기기 전 커밋했던 **마지막 오프셋을 가져옴으로써** <span style='color:#f7b731'>처리하던 스트림의 마지막으로 처리된 지점부터 처리를 재개</span>할 수 있다.
- 로컬 상태 저장소가 유실되었을 경우, 스트림 애플리케이션은 <span style='color:#f7b731'>항상 카프카에 저장된 체인지 로그를 사용해서 로컬 상태 저장소를 복구</span>할 수 있다.
- 카프카 스트림즈는 태스크의 높은 고가용성을 지원하기 위해 카프카의 컨슈머 코디네이션 기능을 사용한다.
- 만약 태스크에 장애가 발생하고 다른 스레드나 인스턴스가 멀쩡히 작동 중이면, 해당 태스크는 사용 가능한 다른 스레드에서 재시작하게 된다.
- 이것은 커슈머 그룹이 컨슈머 중 하나의 장애를 처리하는 것과 유사하다.



## 스트림 처리 활용 사례

스트림 처리는 다음 배치가 실행될 때까지 몇 시간씩 기다리는 것보다 이벤트가 바로바로 처리되기를 원하지만, 응답이 수 밀리초 안에 도착하는 걸 기대하지는 않을 경우 유용하다.

다음은 스트림 처리를 사용해서 해결할 수 있는 몇 가지 실제 시나리오이다.

1. **고객 서비스**
	- chapter 14.6 p.459
2. **사물 인터넷**
	- chapter 14.6 p.459
3. **사기 탐지**
	- chapter 14.6 p.460



## 스트림 처리 프레임워크 선택하기

1. 데이터 수집
	- 하나의 시스템에서 데이터를 다른 시스템으로 전달하는 목적
	- 대상 시스템에 맞춰 약간의 변형이 필요
2. 밀리초 단위 작업
	- 거의 즉각적인 응답을 필요로 하는 애플리케이션
3. 비동기 마이크로서비스
	- 이러한 마이크로서비스는 더 큰 비지니스의 프로세스의 일부로 단일한 기능을 수행한다.
	- 이러한 애플리케이션은 성능 향상을위해 로컬 상태에 이벤트 캐시를 유지해야 할 수 있다.
4. 준 실시간 데이터 분석
	- 이러한 스트림 애플리케이션들은 데이터를 작게 분할해서 비즈니스에 유용한 인사이트를 얻어내기 위해 복잡한 집계 연산과 조인을 수행한다.
5. 시스템 운용성
	- 프로덕션 환경 배포가 쉬운가? 
	- 모니터링과 트러블슈팅이 쉬운가? 
	- 필요로할 때 규모의 확장이나 축소가 용이한가? 
	- 기존의 인프라스트럭처와 잘 통합될 수 있는가?
	- 실수로 인한 재처리를 해야 할 때 어떻게 해야 하는가?
6. 사용 및 디버깅 용이성
	- 개발 시간과 배포에 걸리는 시간은 매우 중요하기 때문에, 효율적인 시스템을 골라야한다.
7. 어려운 일을 쉽게 해줌
	- 대부분의 시스템에서는 고급 윈도우를 집계 연산과 로컬 저장소 유지를 지원한다고는 하지만 아래를 생각해봐야 한다.
		- 개발자가 쉽게 쓸 수 있는가? 
		- 규모 확장, 장애 복구와 같은 너저분한 세부 작동을 알아서 처리해주는지
		- 추상에 구멍이 있거나 직접 엉망이 된 상황을 제어해야 하는지?
	- 즉, 시스템이 더 깔끔한 API와 추상화를 제공하고 너저분한 세부 사항을 알아서 처리할수록 개발자는 더 생산적일 수 있다.
8. 커뮤니티
	- 스트림 프로세싱 애플리케이션이 오픈소스에서 커뮤니티가 활발하면 활발할 수록 좋다.