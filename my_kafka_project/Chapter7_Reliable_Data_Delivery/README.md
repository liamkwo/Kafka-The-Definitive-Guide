## 7장 신뢰성 있는 데이터 전달


### 신뢰성 보장

대게 가장 잘 알려진 신뢰성 보장은 관계형 데이터베이스에서 보편적으로 지원하는 ACID이다. 
이는 <span style='color:#8854d0'>원자성(atomicity), 일관성(consistency), 격리성(isolation) ,지속성(durability)</span>을 의미하며 어떤 데이터베이스가 ACID를 준수한다고 하면, 이는 트랜잭션 처리 관련하여 어떤 행동을 보장함을 의미한다.

이러한 보장이 있기 때문에 가장 중요한 애플리케이션이 관계형 데이터베이스를 믿고 사용할 수 있다. 그렇다면 아파치 카프카는 어떤 것을 보장해줄까?
- 카프카는 파티션 안의 메시지들 간의 순서를 보장한다. 만약 메시지 A 다음에 메시지 B가 쓰여졌다면, 동일한 프로듀서가 동일한 파티션에 썼을 경우, 카프카는 B의 오프셋이 A보다 큰 것을 보장합니다. 컨슈머 역시 A를 읽어온 다음 B를 읽는다.
- 클라이언트가 쓴 메시지는 <span style='color:#f7b731'>모든 인-싱크 레플리카의 파티션에 쓰여진 뒤에야 '커밋'</span>된 것으로 간주된다. **프로듀서는** <span style='color:#f7b731'>메시지가 완전히 커밋된 다음 응답이 올지, 리더에게 쓰여진 다음 응답이 올지 아니면 네트워크로 전송된 다음 응답이 올지</span> **를 선택할 수 있다.**
- 커밋된 메시지들은 <span style='color:#f7b731'>최소 1개의 작동 가능한 레플리카가 남아 있는 한 유실되지 않는다.</span>
- <span style='color:#f7b731'>컨슈머는 커밋된 메시지만</span> 읽을 수 있다.

> 이러한 기본적인 보장들은 신뢰성 있는 시스템 구축을 위해 사용되어질 수 있지만 그 자체로는 시스템 전체를 완전히 신뢰성 있게 만들어 주지는 못한다. 
> 따라서, 개발자나 운영자는 가용성, 높은 처리량, 낮은 지연, 하드웨어 비용, 신뢰성 등 다양한 고려사항에 맞추어 설정 매개변수를 조절함으로써 카프카를 활용해야한다.



### 복제

카프카의 복제 메커니즘은 파티션별로 다수의 레플리카를 유지한다는 특성과 함께 카프카 신뢰성 보장의 핵심이다. 하나의 메시지를 여러 개의 레플리카에 사용함으로써, 카프카는 크래시가 나더라도 메시지의 지속성을 유지한다.

> *6장 카프카의 복제 메커니즘 요약*
> 각 카프카 토픽은 파티션으로 이루어지며, 각 파티션은 하나의 디스크에 저장된다. 카프카는 파티션에 저장된 이벤트들의 순서를 보장하며, 파티션은 다수의 레플리카를 가질 수 있다.(파티션은 온라인 혹은 오프라인 상태일 수 있으며, 레플리카 중 하나가 리더가 된다.) 모든 이벤트들은 리더 레플리카에 의해 쓰여지고읽혀진다. 다른 레플리카들은 단순히 리더와 동기화를 맞추면서 최신 이벤트를 제 시간에 복사하기만 하면 되고, 만약 리더가 작동 불능 상태가 되면, 인-싱크 레플리카 중 하나가 새 리더가 된다.

레플리카는 파티션의 리더 레플리카 이거나 아니면 아래의 조건을 만족하는 팔로워 레플리카인 경우 인-싱크 상태인것으로 간주된다.
- 주키퍼와의 활성 세션이 있다.(하트비트 전송)
- 최근 10초 사이에 리더로부터 메시지를 읽어 왔다.
- 최근 10초 사이에 리더로부터 읽어 온 메시지들이 가장 최근 메시지이다.

> *아웃-오브-싱크 레플리카*
> 동기화가 풀린 레플리카(아웃-오브-싱크 레플리카)는 주키퍼와 다시 연결되어 리더 파티션에 쓰여진 가장 최근 메시지까지 따라잡으면 다시 인-싱크 레플리카가 된다.


### 브로커 설정

#### 복제 팩터

`replication.factor`가 3이라면 각 브로커가 3대의 서로 다른 브로커에 3개 복제됨을 의미한다. 즉, 복제 팩터가 N이면 N+1개의 브로커가 중단되도 토픽의 데이터를 읽거나 쓸 수 있다. 즉, 복제 팩터가 클수록 가용성과 신뢰성은 늘어나고 장애가 발생할 가능성은 줄어든다. 하지만 N배의 디스크 공간이 필요하다.
따라서 <span style='color:#8854d0'>가용성, 지속성, 처리량, 종단 지연, 비용</span> 등 다양한 관점을 고려해 매개변수를 설정해야 한다.
- 가용성: 레플리카 수가 더 많을수록 가용성은 늘어난다.
- 지속성: 복사본이 더 많을수록 모든 데이터가 유실될 가능성은 줄어든다.
- 처리량: 레플리카가 추가될 때마다 브로커간 트래픽이 늘어난다.
- 종단 지연: 쓰여진 메시지를 컨슈머가 읽을 수 있으려면 모든 인-싱크 레플리카에 복제되어야 한다. 

카프카는 언제나 같은 파티션의 레플리카들을 서로 다른 브로커에 저장한다. 하지만 이는 충분히 안전하다고 할 수 없다. 
같은 파티션의 모든 레플리카들이 같은 랙에 설치되어 있는 브로커들에 저장되었는데 <span style='color:#f7b731'>랙 스위치가 오작동할 경우</span> **해당 파티션을 사용할 수 없다.** 
따라서 랙 단위 사고를 방지하기 위해 <span style='color:#f7b731'>브로커를 서로 다른 랙에 배치한 뒤 `broker.rack`브로커 설정 매개변수에 랙 이름을 잡아 줄 것을 권장</span>한다.


#### 언클린 리더 선출

파티션의 리더가 더 이상 사용 가능하지 않을 경우 인-싱크 레플리카 중 하나가 새 리더된다. 만약 <span style='color:#f7b731'>리더가 작동 불능에 빠졌는데</span> **인-싱크 레플리카가 없으면** 어떻게 될까? 이러한 상황은 아래의 두 가지 경우에서 나타난다.
1. 파티션에 3개의 레플리카가 있고, 팔로워 2개가 작동 불능이 된다.(남은 한개는 리더기 때문)
2. 파티션에 3개의 레플리카가 있고, 네트워크 문제로 팔로워 2개의 복제 작업이 뒤쳐졌다.

위의 두 가지 경우 모두, 쉽지 않은 결정을 해야한다.
1. <span style='color:#f7b731'>인-싱크 레플리카 만이 새 리더</span>가 되어야 한다면, <span style='color:#f7b731'>예전 리더가 복구될 때 까지 해당 파티션은</span> **오프라인 상태**가 된다.(얼마나 걸릴지 모른다.)
2. <span style='color:#f7b731'>아웃-오브-싱크 레플리카가 새 리더</span>가 될 수 있다면, 새 리더가 동기화를 못 한 사이 예전 리더에 쓰여졌던 모든 메시지들이 유실되고 컨슈머 입장에서의 일관성 역시 깨진다.

이러한 설정을 `unclean.leader.election.enable`설정을 통해 관리할 수 있다. 기존 설정은 `false`이며 가장 좋은 신뢰성을 제공하는 만큼 가장 안전한 옵션이다. 데이터 유실을 감수하기로 하고 이 값을 **true**로 바꾼 뒤 클러스터를 재시작하는 것도 가능하며, 클러스터가 복구된 뒤 설정 값을 꼭 **false**로 바꿔야한다.


#### 최소 인-싱크 레플리카

커밋된 데이터를 2개 이상의 레플리카에 쓰고자 한다면, `min.insync.replicas`로 인-싱크 레플리카의 최소값을 더 높게 잡아줄 수 있다.


#### 디스크에 저장하기

카프카는 세그먼트를 교체할 때 재시작 직전에만 메시지를 디스크에만 플러시하며, 그 외의 경우는 리눅스의 페이지 캐시 기능에 의존한다.

이러한 발상의 배경에는 각각 데이터의 복제본을 가지고 있는, 서로 다른 랙이나 가용 영역에 위치한 세 대의 장비가 리더의 디스크에 메시지를 쓰는 것보다 더 안전하다는 판단이 있었다. 그래도, 브로커가 디스크에 더 자주 메시지를 저장하도록 설정할 수 는 있다. `flush.messages` 매개변수로 디스크에 저장되지 않은 최대 메시지의 수 를, `flush.ms`로 얼마나 자주 디스크에 메시지를 저장하는지를 조절할 수 있다.



### 신뢰성 있는 시스템에서 프로듀서 사용하기

프로듀서 역시 신뢰성이 있도록 설정을 잡아 주어야 하는데, 아래를 예로 들어볼 수 가 있다.
1. 토픽별로 3개의 레플리카를 가지도록 브로커를 설정하고 언클린 리더 선출 기능을 끈다.
2. 프로듀서가 메시지를 보낼 때 `acks=1`설정으로 보내도록 설정한다.
	- 프로듀서가 메시지를 전송해서<span style='color:#f7b731'> 리더에는 쓰여졌지만, 인-싱크 레플리카에는 반영되지 않은 상태</span>임
	- `acks=1` : 리더만이 메시지를 받았을 때
	- `acks=all` : 모든 인-싱크 레플리카들이 메시지를 받았을 때
	- `acks=0` : 메시지가 보내졌을 때
3. 리더가 프로듀서에게 "메시지가 성공적으로 쓰여짐" 라고 응답을 보낸 직후 <span style='color:#f7b731'>크래시가 나서 데이터가 레플리카로 복제되지 않는다.</span>
4. 아직 아웃-오브-싱크 레플리카가 되기 전이기 때문에, 현재 다른 레플리카들은 인-싱크 레플리카 상태이다. 이 중에서 리더가 선출되면서 프로듀서가 쓴 메시지는 유실 된다.

이를 수정하기 위해서는 신뢰성 요구 조건에 맞는 올바른 `acks`설정을 사용하거나, 설정과 코드 모두에서 에러를 올바르게 처리해야 한다.


#### 프로듀서 재시도 설정하기

일반적으로, **메시지가 유실되지 않는 것이 목표**일 경우 가장 좋은 방법은 재시도 가능한 에러가 발생했을 경우 <span style='color:#f7b731'>프로듀서가 계속해서 메시지 전송을 재시도하도록 설정</span>하는 것이다. 재시도 수를 기본 값인 MAX_INT로 설정하고, 메시지 전송을 포기할 때까지 대기할 수 있는 시간을 지정하는 `delivery.timeout.ms`를 최대로 설정하면 된다.



### 신뢰성 있는 시스템에서 컨슈머 사용하기(4장)

컨슈머는 카프카에 커밋된 데이터만을 읽을 수 있다. 즉, 모든 인-싱크 레플리카에 쓰여진 다음부터 읽을 수 있다. 다르게 말하면, **컨슈머는 오프셋을 이용해 일관성이 보장되는 데이터만 읽는다.**


#### 신뢰성 있는 처리를 위해 중요한 컨슈머 설정

1. **group.id**: 컨슈머가 같은 토픽을 구독할 경우, 각각의 컨슈머는 해당 토픽 전체 파티션의 서로 다른 부분집합이 할당되므로 각 메시지의 다른 부분의 메시지 만을 읽게 된다. 만약 컨슈머가 구독한 토픽의 모든 메시지를 읽어야 한다면 고유한 그룹ID가 필요하다.
2. **auto.offset.reset**: 커밋된 오프셋이 없을 때나 컨슈머가 브로커에 없는 오프셋을 요청할 때 컨슈머가 어떻게 해야 할지를 결정한다. `earliest`, `latest`등을 활용하여 컨슈머의 메시지 읽는 위치를 지정할 수 있다.
3. **enable.auto.commit**: 자동으로 오프셋을 커밋할 지에 대한 여부를 설정한다.
4. **auto.commit.interval.ms**: 오프셋을 자동 커밋할 경우 커밋되는 주기를 설정한다.


#### .컨슈머에서 명시적으로 오프셋 커밋하기

더욱 세밀한 제어를 위해 오프셋 커밋을 직접 수행하고자 한다면 다음과 같은 요소들을 고려해야 한다.
- 메시지 처리 먼저, 오프셋 커밋은 나중에
- 커밋 빈도는 성능과 크래시 발생시 중복 개수 사이의 트레이드오프이다.
- 정확한 시점에 정확한 오프셋을 커밋하자
- 리밸런스
- 컨슈머는 재시도를 해야 할 수도 있다
	- 레코드 30 처리에 실패한 상태에서 31 처리에 성공할 경우, 31을 오프셋을 커밋하면 안 된다.
- 컨슈머가 상태를 유지해야 할 수도 있다.



### 시스템 신뢰성 검증하기

<span style='color:#f7b731'>신뢰성 요구 조건 확인, 브로커 설정, 클라이언트 설정, 활용 사례에 맞는 API 사용이 완료</span>되면 이벤트가 유실되지 않을 거라는 확신을 가지고 프로덕션 환경에서 돌리는 것만 남았다.
카프카 핵심가이드 책에서는 **세 개의 계층에 걸쳐서 검증**을 수행할 것을 제안한다.

1. 설정 검증하기
	- 우리가 선택한 구상이 요구 조건을 충족시킬 수 있는지 확인하는데 도움이 된다.
	- 시스템의 예상 작동을 추론해볼 수 있다.
	- 설정 검증 시나리오(chapter7 p. 200)
2. 애플리케이션 검증하기(우리가 필요로 하는 보장을 해주는지 확인)
	- 애플리케이션 로직이<span style='color:#f7b731'> 카프카의 클라이언트 라이브러리와 상호작용하는 커스텀 에러 코드, 오프셋 커밋, 리밸런스 리스너</span>와 같은 곳들을 확인하는 단계이다.
	- 장애 상황에 대한 시나리오(chapter7 p. 201)
3. 프로덕션 환경에서 신뢰성 모니터링하기
	- 클러스터 상태 모니터링과 클라이언트와 전체 데이터의 흐름 모니터링을 어떻게 할 것인지 확인하는 단계
		- 12장에서 상세히 다룸
	- (chapter7 p. 202)



